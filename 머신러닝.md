# 머신러닝

## 머신러닝의 기초

### 지도학습

- 라벨이 있는 훈련용 데이터에서, <u>여러 특성변수</u>를 이용하여 목표인 라벨을 예측하도록 모델을 학습함.
  - 훈련용 데이터는 원인에 따른 결과값이 주어진 형태의 데이터
- 라벨의 데이터 타입에 따라 연속형이면 **회귀(regression)**, 범주형이면 **분류(classification)**
  - 회귀 : 중고차의 연식, 모델명, 색상, 마모 정도 등등의 특성변수를 이용하여 그 중고차의 가격이 얼마인지 예측하는 알고리즘을 회귀라고한다. (가격은 숫자로 표현되는 연속형)
  - 분류 : 어떤 사람의 여러가지 정보(소득, 나이, 자녀의 수 등등)로 연체를 할 것이냐 말 것이냐와 같은 범주형을 예측하는 문제를 분류라고 한다.

### 비지도 학습

- 라벨이 없는(y값이 없는) 훈련용 데이터에서 특징 변수들 간의 관계나 유사성을 기반응로 의미 있는 패턴을 추출.

#### 군집화

- 거리가 가까운 애들끼리 그룹을 만들어 준다. (클러스터링)

#### 차원축소

- 10만개의 데이터
- 데이터가 너무 많아 특성 변수들만 모아서 차원 축소를 한다.
- 소수의 특성변수만 남긴다.

#### 추천시스템

#### 강화학습



### 모델 기반 지도학습 알고리즘의 일반적인 분석 절차

- 주어진 데이터 전처리 탐색
- 적절한 모델을 선택
- 주어진 데이터로 모델을 훈련시킴
- 훈련된 모델을 적용하여 새로운 데이터에 대한 예측을 수행



#### 과대적합 : Test Error가 Training Error보다 너무 높은 경우

#### 그러나 모형이 너무 단순화 되면 과소적합이 된다. fitting이 안좋은 경우

### k-fold 교차검증

- 3-fold CV(주로 5 ~ 10-fold)
  - train 1, 2 or 1, 3 or 2, 3
  - test 3 or 2 or 1
  - 성능1, 성능2, 성능3 의 Avg

### 과대 적합을 막기 위한 방법

1. 훈련데이터를 많이 확보
2. 모델의 복잡도를 낮춤
   - 특성 변수의 수를 줄이거나 차원 축소
   - 파라미터에 규제를 적용.



### 지도학습 모델의 평가지표

- 레이블이 범주형인 경우 - 분류 모델
  - y가 범주로 표현
- 연속형 숫자형인 경우 - 회귀 모델
  - y가 숫자로 표현

- 평가 : test 데이터의 y값을 train 데이터로 훈련한 모델로 test의 x값을 넣어 출력되는 y값과 얼마나 비슷한지 비교하는 작업

- R-square
  - 선형회귀 모델에서 계산된 경우 0 ~ 1사이의 값을 가지고
  - 0이면 모형이 굉장히 안 좋은 상태, 1이면 모델이 완벽한 피팅을 한 상태 = 오차가 0인 상태
  - 그래서 결정계수 값은 클수록 1에 까까울 수록 좋다.

#### 분류 모델 평가 지표

- |                | Negative    | Positive    |
  | -------------- | ----------- | ----------- |
  | Negative(실제) | A<br />(TN) | B<br />(FP) |
  | Positive(실제) | C<br />(FN) | D<br />(TP) |

  - 정확도 - 전체 관찰치 중 정 분류된 관찰치의 비중 
    (TN + TP) / TN + FP + FN + TP
  - 정밀도(Precision) - Positive로 예측한 것 중에서 실제 범주도 Positive인 데이터의 비율
    TP / FP + TP
  - 재현율(Recall) - 실제 범주가 Positive인 것 중에서 Positive로 예측된 데이터의 비율.
    TP / FN + TP



## Feture Engineering

### 특성공학

- 특성 선택 : 훈련 데이터들 중에서 y를 잘 예측하는 x값들만 뽑는것
- 특성 추출 : 훈련 데이터들을 결합하거나 변형을 통해 새로운 변수를 만들어 낸다.

#### 특성선택

1. Filter 방식 :  각 특성변수를 독립적인 평가 함수로 평가 (1 대 1)
   - 특성하나와 y값 하나를 평가해서 rank를 선정한 뒤 높은 순위의 특성을 선택
   - 실제로 모델을 학습하진 않음, ttest검정이나 카이검정

2. Wrapper 방식 : 학습 알고리즘을 이용. (다 대 1)
   - 다양한 특성 변수의 조합을 통해 그 조합끼리 학습을 시킨다.
   - 특성이 k개 있을때 조합은 2**k - 1개의 조합 생성가능
3. Embedded 방식 : 알고리즘자체에서 변수선택을하고 최적화를 한다.